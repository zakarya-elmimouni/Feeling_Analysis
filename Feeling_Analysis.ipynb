{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feeling analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-Importing Data & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Download the list of stop words if you haven't already\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(text.lower())\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Perform stemming using Porter Stemmer\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
    "\n",
    "\n",
    "    return ({ word: True for word in stemmed_words })\n",
    "\n",
    "def load_training_set():\n",
    "    training = []\n",
    "    folder_train_path=r\"C:\\Users\\Hp\\Desktop\\mes projets\\NLP and  text analysis\\feeling_analysis\\mini_dataset\\train\"\n",
    "    folder_train_path_positive=os.path.join(folder_train_path,'positive')\n",
    "    text_names=os.listdir(folder_train_path_positive)\n",
    "    for text in text_names:\n",
    "        text_path=os.path.join(folder_train_path_positive,text)\n",
    "        with open(text_path, 'r') as file:\n",
    "            contenu = file.read()\n",
    "            training.append([preprocess_text(contenu),'positive'])\n",
    "    folder_train_path_negative=os.path.join(folder_train_path,'negative')\n",
    "    text_names=os.listdir(folder_train_path_negative)\n",
    "    for text in text_names:\n",
    "        text_path=os.path.join(folder_train_path_negative,text)\n",
    "        with open(text_path, 'r') as file:\n",
    "            contenu = file.read()\n",
    "            training.append([preprocess_text(contenu),'negative'])\n",
    "    return training\n",
    "\n",
    "training = load_training_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'bromwel': True, 'high': True, 'cartoon': True, 'comedi': True, '.': True, 'ran': True, 'time': True, 'program': True, 'school': True, 'life': True, ',': True, '``': True, 'teacher': True, \"''\": True, '35': True, 'year': True, 'teach': True, 'profess': True, 'lead': True, 'believ': True, \"'s\": True, 'satir': True, 'much': True, 'closer': True, 'realiti': True, 'scrambl': True, 'surviv': True, 'financi': True, 'insight': True, 'student': True, 'see': True, 'right': True, 'pathet': True, \"'\": True, 'pomp': True, 'petti': True, 'whole': True, 'situat': True, 'remind': True, 'knew': True, 'saw': True, 'episod': True, 'repeatedli': True, 'tri': True, 'burn': True, 'immedi': True, 'recal': True, '.........': True, '..........': True, 'classic': True, 'line': True, ':': True, 'inspector': True, \"'m\": True, 'sack': True, 'one': True, 'welcom': True, 'expect': True, 'mani': True, 'adult': True, 'age': True, 'think': True, 'far': True, 'fetch': True, 'piti': True, \"n't\": True, '!': True}, 'positive'], [{'scott': True, 'bartlett': True, \"'s\": True, \"'offon\": True, \"'\": True, 'nine': True, 'minut': True, 'pure': True, 'crazi': True, '.': True, 'full-front': True, 'assault': True, 'psychedel': True, ',': True, 'pulsat': True, 'epilepsy-induc': True, 'flash': True, 'light': True, 'colour': True, 'first': True, 'true': True, 'merg': True, 'film': True, 'video': True, 'avante-gard': True, 'cinema': True, 'stori': True, 'speak': True, 'use': True, 'imag': True, 'natur': True, 'â–': True, 'particularli': True, 'human': True, 'face': True, 'form': True, 'provok': True, 'sequenc': True, 'emot': True, 'reaction': True, 'integr': True, 'biolog': True, 'phenomena': True, 'highly-industri': True, 'modern': True, 'technolog': True, 'sens': True, 'repres': True, 'tool': True, 'machineri': True, 'theme': True, 'connect': True, 'loos': True, 'subplot': True, 'hal9000': True, 'stanley': True, 'kubrick': True, \"'2001\": True, ':': True, 'space': True, 'odyssey': True, '(': True, '1968': True, ')': True, 'inde': True, 'open': True, 'close-up': True, 'eye': True, 'recal': True, 'dave': True, 'bowman': True, 'journey': True, 'stargat': True, 'visual': True, 'richly-colour': True, 'confront': True, 'blend': True, 'sharp': True, 'vivid': True, 'photographi': True, 'increasingly-graini': True, 'though': True, \"'re\": True, 'sit': True, 'close': True, 'televis': True, 'screen': True, '{': True, 'matter': True, 'fact': True, 'end': True, 'product': True, 'record': True, 'tv': True, 'monitor': True, '}': True, '<': True, 'br': True, '/': True, '>': True, 'appear': True, 'confus': True, 'releas': True, 'date': True, 'imdb': True, 'list': True, '1972': True, 'nation': True, 'registri': True, 'preserv': True, 'foundat': True, 'give': True, 'correct': True, 'year': True, 'perhap': True, 'dispar': True, 'reflect': True, 'time': True, 'complet': True, 'public': True, 'either': True, 'way': True, 'distinctli': True, 'ahead': True, 'occasion': True, 'reminisc': True, '1980': True, 'music': True, 'brisk': True, 'techno': True, 'would': True, \"n't\": True, 'gone': True, 'amiss': True, '!': True, 'captur': True, 'graini': True, 'fragment': True, 'present': True, 'life': True, 'warp': True, 'perspect': True, 'comput': True, 'process': True, 'much': True, 'inform': True, 'thought': True, 'pleas': True, 'laugh': True, 'free-think': True, 'interpret': True, 'extraterrestri': True, 'civilis': True, 'earth': True, 'signal': True, 'might': True, 'well': True, 'receiv': True, 'disjoint': True, 'alien': True, 'document': True, 'bizarr': True, 'montag': True, 'vaguely-familiar': True, 'imageri': True, 'could': True, 'possibl': True, 'make': True, 'coher': True, 'mankind': True, 'eventu': True, 'head': True, 'toward': True, 'irrevers': True, 'puriti': True, 'artifici': True}, 'positive']]\n"
     ]
    }
   ],
   "source": [
    "print(training[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train The Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   worst = True           negati : positi =     25.7 : 1.0\n",
      "                   trier = True           positi : negati =     16.3 : 1.0\n",
      "                 william = True           positi : negati =     13.7 : 1.0\n",
      "                     lar = True           positi : negati =     11.7 : 1.0\n",
      "                  unless = True           negati : positi =     10.3 : 1.0\n",
      "                   peter = True           negati : positi =      9.7 : 1.0\n",
      "                    busi = True           positi : negati =      9.4 : 1.0\n",
      "                   jungl = True           negati : positi =      9.0 : 1.0\n",
      "                   zombi = True           negati : positi =      9.0 : 1.0\n",
      "               brilliant = True           positi : negati =      8.3 : 1.0\n",
      "                 element = True           positi : negati =      7.8 : 1.0\n",
      "                    crap = True           negati : positi =      7.7 : 1.0\n",
      "                 fantast = True           positi : negati =      7.7 : 1.0\n",
      "                  kidnap = True           negati : positi =      7.7 : 1.0\n",
      "                    nake = True           negati : positi =      7.7 : 1.0\n",
      "                    suck = True           negati : positi =      7.7 : 1.0\n",
      "                  highli = True           positi : negati =      7.4 : 1.0\n",
      "                 delight = True           positi : negati =      7.0 : 1.0\n",
      "                 germani = True           positi : negati =      7.0 : 1.0\n",
      "                   uniqu = True           positi : negati =      7.0 : 1.0\n",
      "                  silent = True           positi : negati =      6.6 : 1.0\n",
      "                   badli = True           negati : positi =      6.3 : 1.0\n",
      "                 dorothi = True           negati : positi =      6.3 : 1.0\n",
      "                    gang = True           negati : positi =      6.3 : 1.0\n",
      "                   river = True           negati : positi =      6.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(n=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_set():\n",
    "    training = []\n",
    "    folder_train_path=r\"C:\\Users\\Hp\\Desktop\\mes projets\\NLP and  text analysis\\feeling_analysis\\mini_dataset\\test\"\n",
    "    folder_train_path_positive=os.path.join(folder_train_path,'positive')\n",
    "    text_names=os.listdir(folder_train_path_positive)\n",
    "    for text in text_names:\n",
    "        text_path=os.path.join(folder_train_path_positive,text)\n",
    "        with open(text_path, 'r') as file:\n",
    "            contenu = file.read()\n",
    "            training.append([preprocess_text(contenu),'positive'])\n",
    "    folder_train_path_negative=os.path.join(folder_train_path,'negative')\n",
    "    text_names=os.listdir(folder_train_path_negative)\n",
    "    for text in text_names:\n",
    "        text_path=os.path.join(folder_train_path_negative,text)\n",
    "        with open(text_path, 'r') as file:\n",
    "            contenu = file.read()\n",
    "            training.append([preprocess_text(contenu),'negative'])\n",
    "    return training\n",
    "\n",
    "test = load_test_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7254901960784313\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Assuming you have already trained your Naive Bayes classifier (classifier) and prepared the test data (test)\n",
    "# classifier = NaiveBayesClassifier.train(train)\n",
    "# test = [...]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = nltk.classify.accuracy(classifier, test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the class of a text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n"
     ]
    }
   ],
   "source": [
    "text=\"i'm in a bad situation actually , i can't breathe\"\n",
    "text_to_predict=preprocess_text(text)\n",
    "# Make the prediction using the trained classifier\n",
    "predicted_class = classifier.classify(text_to_predict)\n",
    "print(predicted_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we can use this Model to distuing feedbacks of users in a website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can start by webscrap a website to exatract users's comments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url=\"\"\n",
    "response=requests.get(url)\n",
    "html_content=response.content\n",
    "soup=BeautifulSoup(html_content,'lxml')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "once the text is extracted, we apply preprocessing_text function to prepare the test step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can calculate the number of positive and negaive comments, by setting counters "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
